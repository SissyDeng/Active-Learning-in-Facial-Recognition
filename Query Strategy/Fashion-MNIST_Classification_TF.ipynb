{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os, time\n",
    "import matplotlib.pyplot as plt #from keras.datasets import fashion_mnist\n",
    "from IPython.display import display \n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, Flatten #from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16;\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion-MNIST VGG16.ipynb \u001b[1m\u001b[34mfasion_mnist_data\u001b[m\u001b[m         \u001b[1m\u001b[34mkaras_models\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Fashion-MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('fasion_mnist_data/fashion-mnist_train.zip')\n",
    "test_data = pd.read_csv('fasion_mnist_data/fashion-mnist_test.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape #(60,000*785)\n",
    "test_data.shape #(10000,785)\n",
    "train_X= np.array(train_data.iloc[:,1:])\n",
    "test_X= np.array(test_data.iloc[:,1:])\n",
    "train_Y= np.array (train_data.iloc[:,0]) # (60000,)\n",
    "test_Y = np.array(test_data.iloc[:,0]) #(10000,)\n",
    "\n",
    "\n",
    "# Alternative\n",
    "# from keras.datasets import fashion_mnist\n",
    "# ((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0        30        43         0   \n",
       "3       0  ...         3         0         0         0         0         1   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.unique(train_Y)\n",
    "num_classes = len(classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784, 3), (10000, 784, 3))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the images into 3 channels\n",
    "train_X = np.dstack([train_X] * 3)\n",
    "test_X = np.dstack([test_X] * 3)\n",
    "\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 3), (10000, 28, 28, 3))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape images as per the tensor format required by tensorflow\n",
    "train_X = train_X.reshape(-1, 28, 28, 3)\n",
    "test_X = test_X.reshape(-1, 28, 28, 3)\n",
    "\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 48, 48, 3), (10000, 48, 48, 3))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resize the images 48*48 as required by VGG16\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "train_X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in train_X])\n",
    "test_X = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in test_X])\n",
    "\n",
    "#train_x = preprocess_input(x)\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise the data and change data type\n",
    "train_X = train_X / 255.\n",
    "test_X = test_X / 255.\n",
    "train_X = train_X.astype('float32')\n",
    "test_X = test_X.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Labels to one hot encoded format\n",
    "train_Y_one_hot = to_categorical(train_Y)\n",
    "test_Y_one_hot = to_categorical(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting train data as train and validation data\n",
    "train_X, valid_X, train_label, valid_label = train_test_split(train_X,\n",
    "                                                           train_Y_one_hot,\n",
    "                                                           test_size=0.2,\n",
    "                                                           random_state=27\n",
    "                                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48000, 48, 48, 3), (12000, 48, 48, 3), (48000, 10), (12000, 10))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data size whether it is as per tensorflow and VGG16 requirement\n",
    "train_X.shape, valid_X.shape, train_label.shape, valid_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for instantiating VGG16 model. \n",
    "IMG_WIDTH = 48\n",
    "IMG_HEIGHT = 48\n",
    "IMG_DEPTH = 3\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the input \n",
    "train_X = preprocess_input(train_X)\n",
    "valid_X = preprocess_input(valid_X)\n",
    "test_X  = preprocess_input(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion-MNIST - Classification.ipynb \u001b[1m\u001b[34mkaras_models\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[34mfasion_mnist_data\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG 16 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create base model of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 48, 48, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights='karas_models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                  include_top=False, \n",
    "                  input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH)\n",
    "                 )\n",
    "\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000/48000 [==============================] - 714s 15ms/step\n",
      "10000/10000 [==============================] - 181s 18ms/step\n",
      "12000/12000 [==============================] - 161s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "# Extracting features\n",
    "train_features = conv_base.predict(np.array(train_X), batch_size=BATCH_SIZE, verbose=1)\n",
    "test_features = conv_base.predict(np.array(test_X), batch_size=BATCH_SIZE, verbose=1)\n",
    "val_features = conv_base.predict(np.array(valid_X), batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "#for layer in conv_base.layers:\n",
    "#    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the features so that they can be used for future\n",
    "np.savez(\"train_features\", train_features, train_label)\n",
    "np.savez(\"test_features\", test_features, test_Y)\n",
    "np.savez(\"val_features\", val_features, valid_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 1, 1, 512) \n",
      " (10000, 1, 1, 512) \n",
      " (12000, 1, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "# Current shape of features\n",
    "print(train_features.shape, \"\\n\", test_features.shape, \"\\n\", val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten extracted features\n",
    "train_features_flat = np.reshape(train_features, (48000, 1*1*512))\n",
    "test_features_flat = np.reshape(test_features, (10000, 1*1*512))\n",
    "val_features_flat = np.reshape(val_features, (12000, 1*1*512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add dense layers to output features of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "from keras.layers.advanced_activations import LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the densely connected classifier followed by leakyrelu layer and finally dense layer for the number of classes\n",
    "NB_TRAIN_SAMPLES = train_features_flat.shape[0]\n",
    "NB_VALIDATION_SAMPLES = val_features_flat.shape[0]\n",
    "NB_EPOCHS = 100\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_dim=(1*1*512)))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model.\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=optimizers.Adam(),\n",
    "  # optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "    metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/datax/lib/python3.6/site-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Incorporating reduced learning and early stopping for callback\n",
    "reduce_learning = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    epsilon=0.0001,\n",
    "    cooldown=2,\n",
    "    min_lr=0)\n",
    "\n",
    "eary_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=7,\n",
    "    verbose=1,\n",
    "    mode='auto')\n",
    "\n",
    "callbacks = [reduce_learning, eary_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/datax/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 5s 114us/step - loss: 1.4610 - acc: 0.4613 - val_loss: 1.1438 - val_acc: 0.5887\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 1.0914 - acc: 0.6003 - val_loss: 0.9896 - val_acc: 0.6428\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.9916 - acc: 0.6352 - val_loss: 0.9700 - val_acc: 0.6548\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.9357 - acc: 0.6567 - val_loss: 0.9030 - val_acc: 0.6613\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.9142 - acc: 0.6630 - val_loss: 0.8674 - val_acc: 0.6818\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.8877 - acc: 0.6715 - val_loss: 0.8792 - val_acc: 0.6876\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.8737 - acc: 0.6794 - val_loss: 0.8655 - val_acc: 0.6902\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.8533 - acc: 0.6850 - val_loss: 0.8301 - val_acc: 0.7027\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.8419 - acc: 0.6903 - val_loss: 0.8368 - val_acc: 0.6918\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.8377 - acc: 0.6927 - val_loss: 0.7977 - val_acc: 0.7113\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.8265 - acc: 0.6978 - val_loss: 0.8567 - val_acc: 0.6934\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.8190 - acc: 0.6989 - val_loss: 0.8331 - val_acc: 0.6913\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.7518 - acc: 0.7277 - val_loss: 0.7425 - val_acc: 0.7328\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.7460 - acc: 0.7291 - val_loss: 0.7524 - val_acc: 0.7240\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 5s 96us/step - loss: 0.7449 - acc: 0.7295 - val_loss: 0.7367 - val_acc: 0.7315\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.7406 - acc: 0.7316 - val_loss: 0.7358 - val_acc: 0.7303\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 5s 94us/step - loss: 0.7378 - acc: 0.7308 - val_loss: 0.7576 - val_acc: 0.7202\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.7357 - acc: 0.7325 - val_loss: 0.7305 - val_acc: 0.7303\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.7314 - acc: 0.7347 - val_loss: 0.7226 - val_acc: 0.7413\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.7297 - acc: 0.7343 - val_loss: 0.7217 - val_acc: 0.7398\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.7266 - acc: 0.7353 - val_loss: 0.7223 - val_acc: 0.7375\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 5s 105us/step - loss: 0.7248 - acc: 0.7367 - val_loss: 0.7300 - val_acc: 0.7333\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.7083 - acc: 0.7442 - val_loss: 0.7106 - val_acc: 0.7437\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.7074 - acc: 0.7451 - val_loss: 0.7087 - val_acc: 0.7426\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.7071 - acc: 0.7438 - val_loss: 0.7073 - val_acc: 0.7465\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.7063 - acc: 0.7460 - val_loss: 0.7083 - val_acc: 0.7459\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 5s 94us/step - loss: 0.7055 - acc: 0.7465 - val_loss: 0.7118 - val_acc: 0.7408\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.7024 - acc: 0.7479 - val_loss: 0.7059 - val_acc: 0.7441\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 6s 119us/step - loss: 0.7018 - acc: 0.7479 - val_loss: 0.7056 - val_acc: 0.7454\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 6s 129us/step - loss: 0.7017 - acc: 0.7482 - val_loss: 0.7053 - val_acc: 0.7448\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 5s 107us/step - loss: 0.7014 - acc: 0.7488 - val_loss: 0.7061 - val_acc: 0.7452\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 5s 113us/step - loss: 0.7013 - acc: 0.7486 - val_loss: 0.7057 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.7007 - acc: 0.7490 - val_loss: 0.7049 - val_acc: 0.7445\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 6s 133us/step - loss: 0.7006 - acc: 0.7488 - val_loss: 0.7049 - val_acc: 0.7442\n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.7005 - acc: 0.7490 - val_loss: 0.7049 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.7004 - acc: 0.7490 - val_loss: 0.7048 - val_acc: 0.7448\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.7003 - acc: 0.7493 - val_loss: 0.7048 - val_acc: 0.7446\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 5s 97us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7450\n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 5s 104us/step - loss: 0.7003 - acc: 0.7489 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 6s 115us/step - loss: 0.7003 - acc: 0.7489 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-09.\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 5s 103us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 5.1200004236307e-10.\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 5s 112us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 6s 116us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 6s 130us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0240001069306004e-10.\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 7s 144us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 12s 246us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 2.0480002416167767e-11.\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 13s 266us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 15s 315us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 11s 226us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00056: ReduceLROnPlateau reducing learning rate to 4.096000622011431e-12.\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 9s 188us/step - loss: 0.7003 - acc: 0.7488 - val_loss: 0.7048 - val_acc: 0.7449\n",
      "Epoch 00057: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the the model\n",
    "history = model.fit(\n",
    "    train_features_flat,\n",
    "    train_label,\n",
    "    epochs=NB_EPOCHS,\n",
    "    validation_data=(val_features_flat, valid_label),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the loss and accuracy\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.plot(epochs, acc, 'red', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'blue', label='Validation acc')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Training and validation loss')\n",
    "plt.plot(epochs, loss, 'red', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'blue', label='Validation loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniVGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    " \n",
    "class MiniVGGNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model along with the input shape to be\n",
    "        # \"channels last\" and the channels dimension itself\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "    \n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        # and channels dimension\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "        \n",
    "        # first CONV => RELU => CONV => RELU => POOL layer set\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "            input_shape=inputShape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "    \n",
    "        # second CONV => RELU => CONV => RELU => POOL layer set\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization(axis=chanDim))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "    \n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "    \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "    \n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    " \n",
    "# import the necessary packages\n",
    "from pyimagesearch.minivggnet import MiniVGGNet\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from imutils import build_montages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "# initialize the number of epochs to train for, base learning rate,\n",
    "# and batch size\n",
    "NUM_EPOCHS = 25\n",
    "INIT_LR = 1e-2\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Fashion MNIST...\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 5us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 4s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# grab the Fashion MNIST dataset (if this is your first time running\n",
    "# this the dataset will be automatically downloaded)\n",
    "print(\"[INFO] loading Fashion MNIST...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    " \n",
    "# if we are using \"channels first\" ordering, then reshape the design\n",
    "# matrix such that the matrix is:\n",
    "# num_samples x depth x rows x columns\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    trainX = trainX.reshape((trainX.shape[0], 1, 28, 28))\n",
    "    testX = testX.reshape((testX.shape[0], 1, 28, 28))\n",
    " \n",
    "# otherwise, we are using \"channels last\" ordering, so the design\n",
    "# matrix shape should be: num_samples x rows x columns x depth\n",
    "else:\n",
    "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "    testX = testX.reshape((testX.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to the range of [0, 1]\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    " \n",
    "# one-hot encode the training and testing labels\n",
    "trainY = np_utils.to_categorical(trainY, 10)\n",
    "testY = np_utils.to_categorical(testY, 10)\n",
    " \n",
    "# initialize the label names\n",
    "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\", \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "WARNING:tensorflow:From /anaconda3/envs/datax/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/datax/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "[INFO] training model...\n",
      "WARNING:tensorflow:From /anaconda3/envs/datax/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "60000/60000 [==============================] - 333s 6ms/step - loss: 0.5525 - acc: 0.8139 - val_loss: 0.3217 - val_acc: 0.8853\n",
      "Epoch 2/25\n",
      "60000/60000 [==============================] - 333s 6ms/step - loss: 0.3479 - acc: 0.8757 - val_loss: 0.2817 - val_acc: 0.8969\n",
      "Epoch 3/25\n",
      "60000/60000 [==============================] - 335s 6ms/step - loss: 0.2979 - acc: 0.8927 - val_loss: 0.2509 - val_acc: 0.9070\n",
      "Epoch 4/25\n",
      "60000/60000 [==============================] - 336s 6ms/step - loss: 0.2731 - acc: 0.9022 - val_loss: 0.2390 - val_acc: 0.9103\n",
      "Epoch 5/25\n",
      "60000/60000 [==============================] - 332s 6ms/step - loss: 0.2572 - acc: 0.9064 - val_loss: 0.2249 - val_acc: 0.9161\n",
      "Epoch 6/25\n",
      "60000/60000 [==============================] - 335s 6ms/step - loss: 0.2448 - acc: 0.9109 - val_loss: 0.2224 - val_acc: 0.9165\n",
      "Epoch 7/25\n",
      "60000/60000 [==============================] - 336s 6ms/step - loss: 0.2372 - acc: 0.9137 - val_loss: 0.2174 - val_acc: 0.9199\n",
      "Epoch 8/25\n",
      "60000/60000 [==============================] - 336s 6ms/step - loss: 0.2284 - acc: 0.9162 - val_loss: 0.2132 - val_acc: 0.9224\n",
      "Epoch 9/25\n",
      "60000/60000 [==============================] - 335s 6ms/step - loss: 0.2213 - acc: 0.9205 - val_loss: 0.2102 - val_acc: 0.9224\n",
      "Epoch 10/25\n",
      "60000/60000 [==============================] - 334s 6ms/step - loss: 0.2193 - acc: 0.9206 - val_loss: 0.2106 - val_acc: 0.9224\n",
      "Epoch 11/25\n",
      "60000/60000 [==============================] - 325s 5ms/step - loss: 0.2108 - acc: 0.9230 - val_loss: 0.2095 - val_acc: 0.9232\n",
      "Epoch 12/25\n",
      "60000/60000 [==============================] - 324s 5ms/step - loss: 0.2081 - acc: 0.9242 - val_loss: 0.2047 - val_acc: 0.9241\n",
      "Epoch 13/25\n",
      "60000/60000 [==============================] - 331s 6ms/step - loss: 0.2029 - acc: 0.9263 - val_loss: 0.2039 - val_acc: 0.9262\n",
      "Epoch 14/25\n",
      "60000/60000 [==============================] - 345s 6ms/step - loss: 0.2012 - acc: 0.9269 - val_loss: 0.1983 - val_acc: 0.9276\n",
      "Epoch 15/25\n",
      "60000/60000 [==============================] - 341s 6ms/step - loss: 0.1983 - acc: 0.9284 - val_loss: 0.1980 - val_acc: 0.9266\n",
      "Epoch 16/25\n",
      "60000/60000 [==============================] - 340s 6ms/step - loss: 0.1936 - acc: 0.9293 - val_loss: 0.1942 - val_acc: 0.9297\n",
      "Epoch 17/25\n",
      "60000/60000 [==============================] - 343s 6ms/step - loss: 0.1900 - acc: 0.9305 - val_loss: 0.1937 - val_acc: 0.9295\n",
      "Epoch 18/25\n",
      "60000/60000 [==============================] - 344s 6ms/step - loss: 0.1901 - acc: 0.9296 - val_loss: 0.1935 - val_acc: 0.9282\n",
      "Epoch 19/25\n",
      "60000/60000 [==============================] - 344s 6ms/step - loss: 0.1855 - acc: 0.9315 - val_loss: 0.1919 - val_acc: 0.9303\n",
      "Epoch 20/25\n",
      "60000/60000 [==============================] - 339s 6ms/step - loss: 0.1846 - acc: 0.9330 - val_loss: 0.1921 - val_acc: 0.9301\n",
      "Epoch 21/25\n",
      "60000/60000 [==============================] - 340s 6ms/step - loss: 0.1823 - acc: 0.9331 - val_loss: 0.1919 - val_acc: 0.9301\n",
      "Epoch 22/25\n",
      "60000/60000 [==============================] - 337s 6ms/step - loss: 0.1811 - acc: 0.9332 - val_loss: 0.1877 - val_acc: 0.9305\n",
      "Epoch 23/25\n",
      "60000/60000 [==============================] - 336s 6ms/step - loss: 0.1793 - acc: 0.9356 - val_loss: 0.1888 - val_acc: 0.9314\n",
      "Epoch 24/25\n",
      "60000/60000 [==============================] - 337s 6ms/step - loss: 0.1772 - acc: 0.9346 - val_loss: 0.1894 - val_acc: 0.9304\n",
      "Epoch 25/25\n",
      "60000/60000 [==============================] - 337s 6ms/step - loss: 0.1761 - acc: 0.9345 - val_loss: 0.1891 - val_acc: 0.9303\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)\n",
    "model = MiniVGGNet.build(width=28, height=28, depth=1, classes=10)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    " \n",
    "# train the network\n",
    "print(\"[INFO] training model...\")\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=BS, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         top       0.90      0.87      0.88      1000\n",
      "     trouser       0.99      0.99      0.99      1000\n",
      "    pullover       0.90      0.91      0.90      1000\n",
      "       dress       0.93      0.94      0.93      1000\n",
      "        coat       0.88      0.91      0.89      1000\n",
      "      sandal       0.99      0.98      0.99      1000\n",
      "       shirt       0.80      0.78      0.79      1000\n",
      "     sneaker       0.96      0.98      0.97      1000\n",
      "         bag       0.99      0.99      0.99      1000\n",
      "  ankle boot       0.98      0.96      0.97      1000\n",
      "\n",
      "   micro avg       0.93      0.93      0.93     10000\n",
      "   macro avg       0.93      0.93      0.93     10000\n",
      "weighted avg       0.93      0.93      0.93     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the test set\n",
    "preds = model.predict(testX)\n",
    " \n",
    "# show a nicely formatted classification report\n",
    "print(\"[INFO] evaluating network...\")\n",
    "print(classification_report(testY.argmax(axis=1), preds.argmax(axis=1), target_names=labelNames))\n",
    " \n",
    "# plot the training loss and accuracy\n",
    "N = NUM_EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
